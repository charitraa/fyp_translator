{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa886399",
      "metadata": {
        "id": "fa886399",
        "outputId": "53ff83b4-f8a8-44d5-fe77-32040277bcb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, colorama, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n"
          ]
        }
      ],
      "source": [
        "!pip install torch datasets matplotlib tqdm sacrebleu tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import required modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import os\n",
        "from sacrebleu import corpus_bleu\n",
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers"
      ],
      "metadata": {
        "id": "7_VRKqvbl49q"
      },
      "id": "7_VRKqvbl49q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97458203-971d-4ebd-8b64-92d85ed9b329",
      "metadata": {
        "id": "97458203-971d-4ebd-8b64-92d85ed9b329"
      },
      "outputs": [],
      "source": [
        "# Step 3: Load dataset (English-Nepali)\n",
        "data = load_dataset(\"CohleM/english-to-nepali\")\n",
        "eng_data = data['train']['en']\n",
        "nep_data = data['train']['ne']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97398114",
      "metadata": {
        "id": "97398114",
        "outputId": "f3ab36a7-416e-442e-89a7-1cd6f259fc1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Train and Save BPE Tokenizers\n",
        "with open(\"english.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(eng_data))\n",
        "with open(\"nepali.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(nep_data))\n",
        "\n",
        "eng_tokenizer = Tokenizer(models.BPE())\n",
        "trainer = trainers.BpeTrainer(vocab_size=50000, special_tokens=[\"<pad>\", \"<s>\", \"</s>\"])\n",
        "eng_tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "eng_tokenizer.train([\"english.txt\"], trainer)\n",
        "eng_tokenizer.save(\"eng_tokenizer_50k.json\")\n",
        "\n",
        "nep_tokenizer = Tokenizer(models.BPE())\n",
        "nep_tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "nep_tokenizer.train([\"nepali.txt\"], trainer)\n",
        "nep_tokenizer.save(\"nep_tokenizer_50k.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f8c7510-51f8-44aa-b7f8-e40d836711f9",
      "metadata": {
        "id": "0f8c7510-51f8-44aa-b7f8-e40d836711f9"
      },
      "outputs": [],
      "source": [
        "# Step 5: Load BPE tokenizers\n",
        "eng_tok = Tokenizer.from_file(\"eng_tokenizer_50k.json\")\n",
        "nep_tok = Tokenizer.from_file(\"nep_tokenizer_50k.json\")\n",
        "\n",
        "PAD_ID = 1500\n",
        "SOS_ID = 1501\n",
        "EOS_ID = 1502"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da1adb8a-4e30-4177-8611-67fa48bdf995",
      "metadata": {
        "id": "da1adb8a-4e30-4177-8611-67fa48bdf995",
        "outputId": "9320ab43-5f5a-4d5e-b22e-92d58436863c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Index 0 ---\n",
            "enco_eng_data: [5446, 4095, 481, 412, 4364, 397, 1135, 6002, 16] | <class 'list'>\n",
            "deco_nep_data_sos: [1501, 1149, 1434, 1161, 16996, 10, 24269, 11, 32363, 663, 1665, 3693] | <class 'list'>\n",
            "deco_nep_data_eos: [1149, 1434, 1161, 16996, 10, 24269, 11, 32363, 663, 1665, 3693, 1502] | <class 'list'>\n",
            "--- Index 1 ---\n",
            "enco_eng_data: [961, 7529, 13372, 481, 4163, 400, 14391, 385, 29793, 1044, 854, 3220, 418, 4901, 1279, 397, 546, 454, 1892, 394, 2008, 390, 2992, 2656, 400, 8117, 5089, 397, 4307, 3898, 386, 1966, 239, 3994, 911, 3389, 14, 2051, 390, 31856, 394, 1374, 16] | <class 'list'>\n",
            "deco_nep_data_sos: [1501, 774, 4260, 32363, 10, 612, 4814, 11, 595, 35113, 767, 1161, 3701, 6333, 2164, 14, 2279, 14, 790, 14, 1569, 687, 4260, 266, 1679, 897, 689, 1440, 6569, 8597, 1892, 23803, 15879, 7022, 7719, 815, 823, 2955, 2586, 2778, 4979, 1098] | <class 'list'>\n",
            "deco_nep_data_eos: [774, 4260, 32363, 10, 612, 4814, 11, 595, 35113, 767, 1161, 3701, 6333, 2164, 14, 2279, 14, 790, 14, 1569, 687, 4260, 266, 1679, 897, 689, 1440, 6569, 8597, 1892, 23803, 15879, 7022, 7719, 815, 823, 2955, 2586, 2778, 4979, 1098, 1502] | <class 'list'>\n",
            "--- Index 2 ---\n",
            "enco_eng_data: [35, 1703, 1106, 481, 412, 1863, 397, 14391, 388, 385, 3980, 394, 1046, 2415, 16] | <class 'list'>\n",
            "deco_nep_data_sos: [1501, 1444, 1857, 1306, 1530, 33204, 955, 10, 1609, 11, 5743, 1493, 1532, 3362, 3071, 855, 774, 1175, 823, 2164, 773] | <class 'list'>\n",
            "deco_nep_data_eos: [1444, 1857, 1306, 1530, 33204, 955, 10, 1609, 11, 5743, 1493, 1532, 3362, 3071, 855, 774, 1175, 823, 2164, 773, 1502] | <class 'list'>\n",
            "--- Index 3 ---\n",
            "enco_eng_data: [516, 2583, 876, 764, 398, 833, 7274, 14, 385, 36, 7043, 4464, 26298, 481, 412, 18763, 453, 1222, 1044, 1570, 400, 10880, 394, 1866, 19673, 1863, 453, 4494, 3363, 394, 385, 2303, 696, 16] | <class 'list'>\n",
            "deco_nep_data_sos: [1501, 2527, 1857, 855, 2710, 2874, 2262, 1112, 16996, 969, 663, 10, 8465, 597, 24844, 11, 266, 1114, 815, 26759, 663, 2262, 2077] | <class 'list'>\n",
            "deco_nep_data_eos: [2527, 1857, 855, 2710, 2874, 2262, 1112, 16996, 969, 663, 10, 8465, 597, 24844, 11, 266, 1114, 815, 26759, 663, 2262, 2077, 1502] | <class 'list'>\n",
            "--- Index 4 ---\n",
            "enco_eng_data: [7581, 1404, 32388, 394, 549, 9, 85, 1615, 38961, 434, 662, 4998, 504, 3167, 2777, 394, 17567, 14, 17238, 14, 6912, 14, 15061, 14, 2032, 2422, 388, 603, 2175, 11267, 7007, 840, 3167, 3707, 1125, 664, 434, 707, 16] | <class 'list'>\n",
            "deco_nep_data_sos: [1501, 2783, 14698, 5655, 14, 11911, 14, 4101, 730, 14, 15628, 14, 264, 250, 45581, 3541, 14, 7757, 14, 10729, 6569, 740, 4722, 705, 16, 1709, 7483, 589, 36386, 1908, 2241, 825, 1741, 2254, 4752, 7662, 836, 1178, 979, 2191, 2591, 246] | <class 'list'>\n",
            "deco_nep_data_eos: [2783, 14698, 5655, 14, 11911, 14, 4101, 730, 14, 15628, 14, 264, 250, 45581, 3541, 14, 7757, 14, 10729, 6569, 740, 4722, 705, 16, 1709, 7483, 589, 36386, 1908, 2241, 825, 1741, 2254, 4752, 7662, 836, 1178, 979, 2191, 2591, 246, 1502] | <class 'list'>\n",
            "ğŸ” Verifying each data point before DataLoader...\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Tokenize and prepare training data\n",
        "def encode_ids(tokenizer, text):\n",
        "    return tokenizer.encode(text).ids\n",
        "\n",
        "enco_eng_data = []\n",
        "for i, s in enumerate(eng_data):\n",
        "    ids = eng_tok.encode(s).ids\n",
        "    if isinstance(ids, int):\n",
        "        print(f\"âŒ Error at index {i}: {s} â†’ {ids}\")\n",
        "    assert isinstance(ids, list), f\"ENG {i} is not a list: {ids}\"\n",
        "    enco_eng_data.append(ids)\n",
        "\n",
        "deco_nep_data_sos = []\n",
        "for i, s in enumerate(nep_data):\n",
        "    ids = nep_tok.encode(s).ids\n",
        "    full = [SOS_ID] + ids\n",
        "    assert isinstance(full, list), f\"SOS {i} not list: {full}\"\n",
        "    deco_nep_data_sos.append(full)\n",
        "\n",
        "deco_nep_data_eos = []\n",
        "for i, s in enumerate(nep_data):\n",
        "    ids = nep_tok.encode(s).ids\n",
        "    if isinstance(ids, int):\n",
        "        print(f\"âŒ At index {i}: Nepali '{s}' â†’ got int instead of list: {ids}\")\n",
        "        ids = [ids]  # force wrap it in list to avoid crash\n",
        "    assert isinstance(ids, list), f\"âŒ Expected list, got {type(ids)}\"\n",
        "    deco_nep_data_eos.append(ids + [EOS_ID])\n",
        "\n",
        "# Deep check of your tokenized training data\n",
        "for i in range(5):\n",
        "    print(f\"--- Index {i} ---\")\n",
        "    print(\"enco_eng_data:\", enco_eng_data[i], \"|\", type(enco_eng_data[i]))\n",
        "    print(\"deco_nep_data_sos:\", deco_nep_data_sos[i], \"|\", type(deco_nep_data_sos[i]))\n",
        "    print(\"deco_nep_data_eos:\", deco_nep_data_eos[i], \"|\", type(deco_nep_data_eos[i]))\n",
        "\n",
        "print(\"ğŸ” Verifying each data point before DataLoader...\")\n",
        "for i in range(len(enco_eng_data)):\n",
        "    x, y, z = enco_eng_data[i], deco_nep_data_sos[i], deco_nep_data_eos[i]\n",
        "\n",
        "    if isinstance(x, int):\n",
        "        print(f\"âŒ enco_eng_data[{i}] is int: {x}\")\n",
        "    if isinstance(y, int):\n",
        "        print(f\"âŒ deco_nep_data_sos[{i}] is int: {y}\")\n",
        "    if isinstance(z, int):\n",
        "        print(f\"âŒ deco_nep_data_eos[{i}] is int: {z}\")\n",
        "\n",
        "    if not isinstance(x, list):\n",
        "        print(f\"âŒ enco_eng_data[{i}] is not list: {x}\")\n",
        "    if not isinstance(y, list):\n",
        "        print(f\"âŒ deco_nep_data_sos[{i}] is not list: {y}\")\n",
        "    if not isinstance(z, list):\n",
        "        print(f\"âŒ deco_nep_data_eos[{i}] is not list: {z}\")\n",
        "\n",
        "    for tok in x:\n",
        "        if not isinstance(tok, int):\n",
        "            print(f\"âŒ Non-int token in enco_eng_data[{i}]: {tok}\")\n",
        "    for tok in y:\n",
        "        if not isinstance(tok, int):\n",
        "            print(f\"âŒ Non-int token in deco_nep_data_sos[{i}]: {tok}\")\n",
        "    for tok in z:\n",
        "        if not isinstance(tok, int):\n",
        "            print(f\"âŒ Non-int token in deco_nep_data_eos[{i}]: {tok}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30afa48c-e37a-4895-a76a-d3e5f7f9a823",
      "metadata": {
        "id": "30afa48c-e37a-4895-a76a-d3e5f7f9a823",
        "outputId": "7b25ebed-7351-4ff3-cb63-7f6ce746aa2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking sample 0\n",
            "ENG: [5446, 4095, 481, 412, 4364, 397, 1135, 6002, 16] (<class 'list'>), NEP-SOS: [1501, 1149, 1434, 1161, 16996, 10, 24269, 11, 32363, 663, 1665, 3693] (<class 'list'>), NEP-EOS: [1149, 1434, 1161, 16996, 10, 24269, 11, 32363, 663, 1665, 3693, 1502] (<class 'list'>)\n",
            "Checking sample 1\n",
            "ENG: [961, 7529, 13372, 481, 4163, 400, 14391, 385, 29793, 1044, 854, 3220, 418, 4901, 1279, 397, 546, 454, 1892, 394, 2008, 390, 2992, 2656, 400, 8117, 5089, 397, 4307, 3898, 386, 1966, 239, 3994, 911, 3389, 14, 2051, 390, 31856, 394, 1374, 16] (<class 'list'>), NEP-SOS: [1501, 774, 4260, 32363, 10, 612, 4814, 11, 595, 35113, 767, 1161, 3701, 6333, 2164, 14, 2279, 14, 790, 14, 1569, 687, 4260, 266, 1679, 897, 689, 1440, 6569, 8597, 1892, 23803, 15879, 7022, 7719, 815, 823, 2955, 2586, 2778, 4979, 1098] (<class 'list'>), NEP-EOS: [774, 4260, 32363, 10, 612, 4814, 11, 595, 35113, 767, 1161, 3701, 6333, 2164, 14, 2279, 14, 790, 14, 1569, 687, 4260, 266, 1679, 897, 689, 1440, 6569, 8597, 1892, 23803, 15879, 7022, 7719, 815, 823, 2955, 2586, 2778, 4979, 1098, 1502] (<class 'list'>)\n",
            "Checking sample 2\n",
            "ENG: [35, 1703, 1106, 481, 412, 1863, 397, 14391, 388, 385, 3980, 394, 1046, 2415, 16] (<class 'list'>), NEP-SOS: [1501, 1444, 1857, 1306, 1530, 33204, 955, 10, 1609, 11, 5743, 1493, 1532, 3362, 3071, 855, 774, 1175, 823, 2164, 773] (<class 'list'>), NEP-EOS: [1444, 1857, 1306, 1530, 33204, 955, 10, 1609, 11, 5743, 1493, 1532, 3362, 3071, 855, 774, 1175, 823, 2164, 773, 1502] (<class 'list'>)\n",
            "Checking sample 3\n",
            "ENG: [516, 2583, 876, 764, 398, 833, 7274, 14, 385, 36, 7043, 4464, 26298, 481, 412, 18763, 453, 1222, 1044, 1570, 400, 10880, 394, 1866, 19673, 1863, 453, 4494, 3363, 394, 385, 2303, 696, 16] (<class 'list'>), NEP-SOS: [1501, 2527, 1857, 855, 2710, 2874, 2262, 1112, 16996, 969, 663, 10, 8465, 597, 24844, 11, 266, 1114, 815, 26759, 663, 2262, 2077] (<class 'list'>), NEP-EOS: [2527, 1857, 855, 2710, 2874, 2262, 1112, 16996, 969, 663, 10, 8465, 597, 24844, 11, 266, 1114, 815, 26759, 663, 2262, 2077, 1502] (<class 'list'>)\n",
            "Checking sample 4\n",
            "ENG: [7581, 1404, 32388, 394, 549, 9, 85, 1615, 38961, 434, 662, 4998, 504, 3167, 2777, 394, 17567, 14, 17238, 14, 6912, 14, 15061, 14, 2032, 2422, 388, 603, 2175, 11267, 7007, 840, 3167, 3707, 1125, 664, 434, 707, 16] (<class 'list'>), NEP-SOS: [1501, 2783, 14698, 5655, 14, 11911, 14, 4101, 730, 14, 15628, 14, 264, 250, 45581, 3541, 14, 7757, 14, 10729, 6569, 740, 4722, 705, 16, 1709, 7483, 589, 36386, 1908, 2241, 825, 1741, 2254, 4752, 7662, 836, 1178, 979, 2191, 2591, 246] (<class 'list'>), NEP-EOS: [2783, 14698, 5655, 14, 11911, 14, 4101, 730, 14, 15628, 14, 264, 250, 45581, 3541, 14, 7757, 14, 10729, 6569, 740, 4722, 705, 16, 1709, 7483, 589, 36386, 1908, 2241, 825, 1741, 2254, 4752, 7662, 836, 1178, 979, 2191, 2591, 246, 1502] (<class 'list'>)\n",
            "ğŸ” Testing DataLoader batching...\n",
            "âœ… Batch 1\n",
            " - Input shape : torch.Size([16, 63])\n",
            " - Target shape: torch.Size([16, 63])\n",
            " - Output shape: torch.Size([16, 63])\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Dataset & DataLoader\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, input_data, target_data, output_data):\n",
        "        self.input_data = input_data\n",
        "        self.target_data = target_data\n",
        "        self.output_data = output_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_data[idx], self.target_data[idx], self.output_data[idx]\n",
        "\n",
        "def pad_batch(batch):\n",
        "    input_seqs, target_seqs, output_seqs = zip(*batch)\n",
        "\n",
        "    def validate(group, name):\n",
        "        for i, seq in enumerate(group):\n",
        "            if isinstance(seq, int):\n",
        "                raise TypeError(f\"âŒ {name}[{i}] is an int instead of list: {seq}\")\n",
        "            if not isinstance(seq, list):\n",
        "                raise TypeError(f\"âŒ {name}[{i}] is not list: {type(seq)} -> {seq}\")\n",
        "            for j, tok in enumerate(seq):\n",
        "                if not isinstance(tok, int):\n",
        "                    raise TypeError(f\"âŒ {name}[{i}][{j}] is not int: {type(tok)} -> {tok}\")\n",
        "\n",
        "    validate(input_seqs, \"input_seqs\")\n",
        "    validate(target_seqs, \"target_seqs\")\n",
        "    validate(output_seqs, \"output_seqs\")\n",
        "\n",
        "    max_len = max(len(seq) for seq in input_seqs + target_seqs + output_seqs)\n",
        "    pad_tensor = lambda seq: seq + [PAD_ID] * (max_len - len(seq))\n",
        "\n",
        "    try:\n",
        "        return (\n",
        "            torch.tensor([pad_tensor(s) for s in input_seqs]),\n",
        "            torch.tensor([pad_tensor(s) for s in target_seqs]),\n",
        "            torch.tensor([pad_tensor(s) for s in output_seqs])\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\"âš ï¸ ERROR DURING TENSOR CONVERSION:\")\n",
        "        print(\"Sample input_seqs:\", input_seqs[:3])\n",
        "        print(\"Sample target_seqs:\", target_seqs[:3])\n",
        "        print(\"Sample output_seqs:\", output_seqs[:3])\n",
        "        raise e\n",
        "\n",
        "\n",
        "\n",
        "dataset = TranslationDataset(enco_eng_data, deco_nep_data_sos, deco_nep_data_eos)\n",
        "train_loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=pad_batch)\n",
        "for i in range(5):\n",
        "    print(f\"Checking sample {i}\")\n",
        "    x, y, z = enco_eng_data[i], deco_nep_data_sos[i], deco_nep_data_eos[i]\n",
        "    print(f\"ENG: {x} ({type(x)}), NEP-SOS: {y} ({type(y)}), NEP-EOS: {z} ({type(z)})\")\n",
        "    for t in [x, y, z]:\n",
        "        assert isinstance(t, list), f\"âŒ Not list: {t}\"\n",
        "        for token in t:\n",
        "            assert isinstance(token, int), f\"âŒ Not int: {token} in {t}\"\n",
        "print(\"ğŸ” Testing DataLoader batching...\")\n",
        "for batch_idx, (src, tgt, out) in enumerate(train_loader):\n",
        "    print(f\"âœ… Batch {batch_idx+1}\")\n",
        "    print(\" - Input shape :\", src.shape)\n",
        "    print(\" - Target shape:\", tgt.shape)\n",
        "    print(\" - Output shape:\", out.shape)\n",
        "    break  # Just check the first batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79142c55-12c6-4362-b2dc-e05d38db8650",
      "metadata": {
        "id": "79142c55-12c6-4362-b2dc-e05d38db8650"
      },
      "outputs": [],
      "source": [
        "# Step 8: Transformer Model\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, embd, heads, dropout):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(embd, heads, dropout=dropout, batch_first=True)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embd, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, embd)\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(embd)\n",
        "        self.norm2 = nn.LayerNorm(embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_out, _ = self.attn(x, x, x)\n",
        "        x = self.norm1(x + attn_out)\n",
        "        ff_out = self.ff(x)\n",
        "        return self.norm2(x + ff_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c68e3bec-c546-4426-817b-000aa2c84ce4",
      "metadata": {
        "id": "c68e3bec-c546-4426-817b-000aa2c84ce4"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, embd, heads, dropout):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(embd, heads, dropout=dropout, batch_first=True)\n",
        "        self.cross_attn = nn.MultiheadAttention(embd, heads, dropout=dropout, batch_first=True)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embd, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, embd)\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(embd)\n",
        "        self.norm2 = nn.LayerNorm(embd)\n",
        "        self.norm3 = nn.LayerNorm(embd)\n",
        "\n",
        "    def forward(self, x, enc_out):\n",
        "        self_attn_out, _ = self.self_attn(x, x, x, attn_mask=torch.triu(torch.ones(x.size(1), x.size(1)) * float('-inf'), diagonal=1).to(x.device))\n",
        "        x = self.norm1(x + self_attn_out)\n",
        "        cross_attn_out, _ = self.cross_attn(x, enc_out, enc_out)\n",
        "        x = self.norm2(x + cross_attn_out)\n",
        "        ff_out = self.ff(x)\n",
        "        return self.norm3(x + ff_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36c59a64-d037-40d3-9e5c-22fd71a8024f",
      "metadata": {
        "id": "36c59a64-d037-40d3-9e5c-22fd71a8024f"
      },
      "outputs": [],
      "source": [
        "class TranslationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embd, heads, layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embd)\n",
        "        self.pe = nn.Embedding(500, embd)\n",
        "        self.encoder = nn.Sequential(*[EncoderBlock(embd, heads, dropout) for _ in range(layers)])\n",
        "        self.decoder = nn.ModuleList([DecoderBlock(embd, heads, dropout) for _ in range(layers)])\n",
        "        self.ln = nn.LayerNorm(embd)\n",
        "        self.out = nn.Linear(embd, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        seq_len = src.size(1)\n",
        "        pos = torch.arange(seq_len, device=src.device).unsqueeze(0)\n",
        "        src = self.embed(src) + self.pe(pos)\n",
        "        enc_out = self.encoder(src)\n",
        "\n",
        "        tgt_len = tgt.size(1)\n",
        "        pos_t = torch.arange(tgt_len, device=src.device).unsqueeze(0)\n",
        "        tgt = self.embed(tgt) + self.pe(pos_t)\n",
        "        for layer in self.decoder:\n",
        "            tgt = layer(tgt, enc_out)\n",
        "\n",
        "        return self.out(self.ln(tgt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0110c900-4a9a-457b-8d3d-75ad8bbccdc6",
      "metadata": {
        "id": "0110c900-4a9a-457b-8d3d-75ad8bbccdc6",
        "outputId": "50cd81d7-5b7b-45e6-eab3-635c84f47bec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   1%|â–         | 158/11084 [04:12<4:50:49,  1.60s/it] \n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cpu\")  # or 'cuda' if available\n",
        "model = TranslationModel(vocab_size=50000, embd=256, heads=8, layers=4, dropout=0.1).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
        "\n",
        "train_loss = []\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for src, tgt, out in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        src, tgt, out = src.to(device), tgt.to(device), out.to(device)\n",
        "        logits = model(src, tgt)\n",
        "        loss = loss_fn(logits.view(-1, logits.size(-1)), out.view(-1))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg = total_loss / len(train_loader)\n",
        "    train_loss.append(avg)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg:.4f}\")\n",
        "    torch.save(model.state_dict(), f\"transformer_epoch{epoch+1}.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "812d17a3-f73f-4b33-a8b0-2e41185ed71d",
      "metadata": {
        "id": "812d17a3-f73f-4b33-a8b0-2e41185ed71d",
        "outputId": "c5de7e06-b1b8-40cf-a440-78369ad55035"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Step 10: Plot Loss\n",
        "plt.plot(train_loss, marker='o')\n",
        "plt.title(\"Transformer NMT Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ebbc593-3646-48ac-a0d7-f6dc86164140",
      "metadata": {
        "id": "6ebbc593-3646-48ac-a0d7-f6dc86164140"
      },
      "outputs": [],
      "source": [
        "# Step 11: Translation function\n",
        "def translate(sentence, max_len=30):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        input_ids = torch.tensor([encode_ids(eng_tok, sentence)]).to('cuda')\n",
        "        pos = torch.arange(input_ids.size(1), device='cuda').unsqueeze(0)\n",
        "        enc_out = model.encoder(model.embed(input_ids) + model.pe(pos))\n",
        "\n",
        "        tgt_ids = torch.tensor([[SOS_ID]]).to('cuda')\n",
        "        for _ in range(max_len):\n",
        "            pos_t = torch.arange(tgt_ids.size(1), device='cuda').unsqueeze(0)\n",
        "            x = model.embed(tgt_ids) + model.pe(pos_t)\n",
        "            for layer in model.decoder:\n",
        "                x = layer(x, enc_out)\n",
        "            output = model.out(model.ln(x))\n",
        "            next_token = output[:, -1, :].argmax(dim=-1)\n",
        "            tgt_ids = torch.cat([tgt_ids, next_token.unsqueeze(1)], dim=1)\n",
        "            if next_token.item() == EOS_ID:\n",
        "                break\n",
        "        return nep_tok.decode(tgt_ids[0, 1:-1].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2ea4afc-5d08-4f25-b985-907da855acc4",
      "metadata": {
        "id": "c2ea4afc-5d08-4f25-b985-907da855acc4",
        "outputId": "0f8ca2d1-4c81-44cc-9257-dc104a03ef59"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m refs = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m50\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     pred = \u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meng_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     ref = nep_data[i]\n\u001b[32m      7\u001b[39m     preds.append(pred)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtranslate\u001b[39m\u001b[34m(sentence, max_len)\u001b[39m\n\u001b[32m      3\u001b[39m model.eval()\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     input_ids = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencode_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43meng_tok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     pos = torch.arange(input_ids.size(\u001b[32m1\u001b[39m), device=\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m).unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m      7\u001b[39m     enc_out = model.encoder(model.embed(input_ids) + model.pe(pos))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/fyp/env/lib/python3.12/site-packages/torch/cuda/__init__.py:372\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m    371\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mLAZY\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[32m    376\u001b[39m _tls.is_initializing = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[31mRuntimeError\u001b[39m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "# Step 12: Evaluate with BLEU\n",
        "preds = []\n",
        "refs = []\n",
        "for i in range(50):\n",
        "    pred = translate(eng_data[i])\n",
        "    ref = nep_data[i]\n",
        "    preds.append(pred)\n",
        "    refs.append([ref])\n",
        "print(\"BLEU Score:\", corpus_bleu(preds, refs).score)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}