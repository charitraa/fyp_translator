{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa886399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import required modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from sacrebleu import corpus_bleu\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97458203-971d-4ebd-8b64-92d85ed9b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load dataset (English-Nepali)\n",
    "data = load_dataset(\"CohleM/english-to-nepali\")\n",
    "eng_data = data['train']['en']\n",
    "nep_data = data['train']['ne']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97398114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train and Save BPE Tokenizers\n",
    "with open(\"english.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(eng_data))\n",
    "with open(\"nepali.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(nep_data))\n",
    "\n",
    "eng_tokenizer = Tokenizer(models.BPE())\n",
    "trainer = trainers.BpeTrainer(vocab_size=50000, special_tokens=[\"<pad>\", \"<s>\", \"</s>\"])\n",
    "eng_tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "eng_tokenizer.train([\"english.txt\"], trainer)\n",
    "eng_tokenizer.save(\"eng_tokenizer_50k.json\")\n",
    "\n",
    "nep_tokenizer = Tokenizer(models.BPE())\n",
    "nep_tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "nep_tokenizer.train([\"nepali.txt\"], trainer)\n",
    "nep_tokenizer.save(\"nep_tokenizer_50k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f8c7510-51f8-44aa-b7f8-e40d836711f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Load BPE tokenizers\n",
    "eng_tok = Tokenizer.from_file(\"eng_tokenizer_50k.json\")\n",
    "nep_tok = Tokenizer.from_file(\"nep_tokenizer_50k.json\")\n",
    "\n",
    "PAD_ID = 1500\n",
    "SOS_ID = 1501\n",
    "EOS_ID = 1502"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da1adb8a-4e30-4177-8611-67fa48bdf995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Index 0 ---\n",
      "enco_eng_data: [5446, 4095, 481, 412, 4364, 397, 1135, 6002, 16] | <class 'list'>\n",
      "deco_nep_data_sos: [1501, 1149, 1434, 1161, 16996, 10, 24269, 11, 32363, 663, 1665, 3693] | <class 'list'>\n",
      "deco_nep_data_eos: [1149, 1434, 1161, 16996, 10, 24269, 11, 32363, 663, 1665, 3693, 1502] | <class 'list'>\n",
      "--- Index 1 ---\n",
      "enco_eng_data: [961, 7529, 13372, 481, 4163, 400, 14391, 385, 29793, 1044, 854, 3220, 418, 4901, 1279, 397, 546, 454, 1892, 394, 2008, 390, 2992, 2656, 400, 8117, 5089, 397, 4307, 3898, 386, 1966, 239, 3994, 911, 3389, 14, 2051, 390, 31856, 394, 1374, 16] | <class 'list'>\n",
      "deco_nep_data_sos: [1501, 774, 4260, 32363, 10, 612, 4814, 11, 595, 35113, 767, 1161, 3701, 6333, 2164, 14, 2279, 14, 790, 14, 1569, 687, 4260, 266, 1679, 897, 689, 1440, 6569, 8597, 1892, 23803, 15879, 7022, 7719, 815, 823, 2955, 2586, 2778, 4979, 1098] | <class 'list'>\n",
      "deco_nep_data_eos: [774, 4260, 32363, 10, 612, 4814, 11, 595, 35113, 767, 1161, 3701, 6333, 2164, 14, 2279, 14, 790, 14, 1569, 687, 4260, 266, 1679, 897, 689, 1440, 6569, 8597, 1892, 23803, 15879, 7022, 7719, 815, 823, 2955, 2586, 2778, 4979, 1098, 1502] | <class 'list'>\n",
      "--- Index 2 ---\n",
      "enco_eng_data: [35, 1703, 1106, 481, 412, 1863, 397, 14391, 388, 385, 3980, 394, 1046, 2415, 16] | <class 'list'>\n",
      "deco_nep_data_sos: [1501, 1444, 1857, 1306, 1530, 33204, 955, 10, 1609, 11, 5743, 1493, 1532, 3362, 3071, 855, 774, 1175, 823, 2164, 773] | <class 'list'>\n",
      "deco_nep_data_eos: [1444, 1857, 1306, 1530, 33204, 955, 10, 1609, 11, 5743, 1493, 1532, 3362, 3071, 855, 774, 1175, 823, 2164, 773, 1502] | <class 'list'>\n",
      "--- Index 3 ---\n",
      "enco_eng_data: [516, 2583, 876, 764, 398, 833, 7274, 14, 385, 36, 7043, 4464, 26298, 481, 412, 18763, 453, 1222, 1044, 1570, 400, 10880, 394, 1866, 19673, 1863, 453, 4494, 3363, 394, 385, 2303, 696, 16] | <class 'list'>\n",
      "deco_nep_data_sos: [1501, 2527, 1857, 855, 2710, 2874, 2262, 1112, 16996, 969, 663, 10, 8465, 597, 24844, 11, 266, 1114, 815, 26759, 663, 2262, 2077] | <class 'list'>\n",
      "deco_nep_data_eos: [2527, 1857, 855, 2710, 2874, 2262, 1112, 16996, 969, 663, 10, 8465, 597, 24844, 11, 266, 1114, 815, 26759, 663, 2262, 2077, 1502] | <class 'list'>\n",
      "--- Index 4 ---\n",
      "enco_eng_data: [7581, 1404, 32388, 394, 549, 9, 85, 1615, 38961, 434, 662, 4998, 504, 3167, 2777, 394, 17567, 14, 17238, 14, 6912, 14, 15061, 14, 2032, 2422, 388, 603, 2175, 11267, 7007, 840, 3167, 3707, 1125, 664, 434, 707, 16] | <class 'list'>\n",
      "deco_nep_data_sos: [1501, 2783, 14698, 5655, 14, 11911, 14, 4101, 730, 14, 15628, 14, 264, 250, 45581, 3541, 14, 7757, 14, 10729, 6569, 740, 4722, 705, 16, 1709, 7483, 589, 36386, 1908, 2241, 825, 1741, 2254, 4752, 7662, 836, 1178, 979, 2191, 2591, 246] | <class 'list'>\n",
      "deco_nep_data_eos: [2783, 14698, 5655, 14, 11911, 14, 4101, 730, 14, 15628, 14, 264, 250, 45581, 3541, 14, 7757, 14, 10729, 6569, 740, 4722, 705, 16, 1709, 7483, 589, 36386, 1908, 2241, 825, 1741, 2254, 4752, 7662, 836, 1178, 979, 2191, 2591, 246, 1502] | <class 'list'>\n",
      "üîé Verifying each data point before DataLoader...\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Tokenize and prepare training data\n",
    "def encode_ids(tokenizer, text):\n",
    "    return tokenizer.encode(text).ids\n",
    "\n",
    "enco_eng_data = []\n",
    "for i, s in enumerate(eng_data):\n",
    "    ids = eng_tok.encode(s).ids\n",
    "    if isinstance(ids, int):\n",
    "        print(f\"‚ùå Error at index {i}: {s} ‚Üí {ids}\")\n",
    "    assert isinstance(ids, list), f\"ENG {i} is not a list: {ids}\"\n",
    "    enco_eng_data.append(ids)\n",
    "\n",
    "deco_nep_data_sos = []\n",
    "for i, s in enumerate(nep_data):\n",
    "    ids = nep_tok.encode(s).ids\n",
    "    full = [SOS_ID] + ids\n",
    "    assert isinstance(full, list), f\"SOS {i} not list: {full}\"\n",
    "    deco_nep_data_sos.append(full)\n",
    "\n",
    "deco_nep_data_eos = []\n",
    "for i, s in enumerate(nep_data):\n",
    "    ids = nep_tok.encode(s).ids\n",
    "    if isinstance(ids, int):\n",
    "        print(f\"‚ùå At index {i}: Nepali '{s}' ‚Üí got int instead of list: {ids}\")\n",
    "        ids = [ids]  # force wrap it in list to avoid crash\n",
    "    assert isinstance(ids, list), f\"‚ùå Expected list, got {type(ids)}\"\n",
    "    deco_nep_data_eos.append(ids + [EOS_ID])\n",
    "\n",
    "# Deep check of your tokenized training data\n",
    "for i in range(5):\n",
    "    print(f\"--- Index {i} ---\")\n",
    "    print(\"enco_eng_data:\", enco_eng_data[i], \"|\", type(enco_eng_data[i]))\n",
    "    print(\"deco_nep_data_sos:\", deco_nep_data_sos[i], \"|\", type(deco_nep_data_sos[i]))\n",
    "    print(\"deco_nep_data_eos:\", deco_nep_data_eos[i], \"|\", type(deco_nep_data_eos[i]))\n",
    "\n",
    "print(\"üîé Verifying each data point before DataLoader...\")\n",
    "for i in range(len(enco_eng_data)):\n",
    "    x, y, z = enco_eng_data[i], deco_nep_data_sos[i], deco_nep_data_eos[i]\n",
    "    \n",
    "    if isinstance(x, int):\n",
    "        print(f\"‚ùå enco_eng_data[{i}] is int: {x}\")\n",
    "    if isinstance(y, int):\n",
    "        print(f\"‚ùå deco_nep_data_sos[{i}] is int: {y}\")\n",
    "    if isinstance(z, int):\n",
    "        print(f\"‚ùå deco_nep_data_eos[{i}] is int: {z}\")\n",
    "\n",
    "    if not isinstance(x, list):\n",
    "        print(f\"‚ùå enco_eng_data[{i}] is not list: {x}\")\n",
    "    if not isinstance(y, list):\n",
    "        print(f\"‚ùå deco_nep_data_sos[{i}] is not list: {y}\")\n",
    "    if not isinstance(z, list):\n",
    "        print(f\"‚ùå deco_nep_data_eos[{i}] is not list: {z}\")\n",
    "\n",
    "    for tok in x:\n",
    "        if not isinstance(tok, int):\n",
    "            print(f\"‚ùå Non-int token in enco_eng_data[{i}]: {tok}\")\n",
    "    for tok in y:\n",
    "        if not isinstance(tok, int):\n",
    "            print(f\"‚ùå Non-int token in deco_nep_data_sos[{i}]: {tok}\")\n",
    "    for tok in z:\n",
    "        if not isinstance(tok, int):\n",
    "            print(f\"‚ùå Non-int token in deco_nep_data_eos[{i}]: {tok}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30afa48c-e37a-4895-a76a-d3e5f7f9a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking sample 0\n",
      "ENG: [5446, 4095, 481, 412, 4364, 397, 1135, 6002, 16] (<class 'list'>), NEP-SOS: [1501, 1149, 1434, 1161, 16996, 10, 24269, 11, 32363, 663, 1665, 3693] (<class 'list'>), NEP-EOS: [1149, 1434, 1161, 16996, 10, 24269, 11, 32363, 663, 1665, 3693, 1502] (<class 'list'>)\n",
      "Checking sample 1\n",
      "ENG: [961, 7529, 13372, 481, 4163, 400, 14391, 385, 29793, 1044, 854, 3220, 418, 4901, 1279, 397, 546, 454, 1892, 394, 2008, 390, 2992, 2656, 400, 8117, 5089, 397, 4307, 3898, 386, 1966, 239, 3994, 911, 3389, 14, 2051, 390, 31856, 394, 1374, 16] (<class 'list'>), NEP-SOS: [1501, 774, 4260, 32363, 10, 612, 4814, 11, 595, 35113, 767, 1161, 3701, 6333, 2164, 14, 2279, 14, 790, 14, 1569, 687, 4260, 266, 1679, 897, 689, 1440, 6569, 8597, 1892, 23803, 15879, 7022, 7719, 815, 823, 2955, 2586, 2778, 4979, 1098] (<class 'list'>), NEP-EOS: [774, 4260, 32363, 10, 612, 4814, 11, 595, 35113, 767, 1161, 3701, 6333, 2164, 14, 2279, 14, 790, 14, 1569, 687, 4260, 266, 1679, 897, 689, 1440, 6569, 8597, 1892, 23803, 15879, 7022, 7719, 815, 823, 2955, 2586, 2778, 4979, 1098, 1502] (<class 'list'>)\n",
      "Checking sample 2\n",
      "ENG: [35, 1703, 1106, 481, 412, 1863, 397, 14391, 388, 385, 3980, 394, 1046, 2415, 16] (<class 'list'>), NEP-SOS: [1501, 1444, 1857, 1306, 1530, 33204, 955, 10, 1609, 11, 5743, 1493, 1532, 3362, 3071, 855, 774, 1175, 823, 2164, 773] (<class 'list'>), NEP-EOS: [1444, 1857, 1306, 1530, 33204, 955, 10, 1609, 11, 5743, 1493, 1532, 3362, 3071, 855, 774, 1175, 823, 2164, 773, 1502] (<class 'list'>)\n",
      "Checking sample 3\n",
      "ENG: [516, 2583, 876, 764, 398, 833, 7274, 14, 385, 36, 7043, 4464, 26298, 481, 412, 18763, 453, 1222, 1044, 1570, 400, 10880, 394, 1866, 19673, 1863, 453, 4494, 3363, 394, 385, 2303, 696, 16] (<class 'list'>), NEP-SOS: [1501, 2527, 1857, 855, 2710, 2874, 2262, 1112, 16996, 969, 663, 10, 8465, 597, 24844, 11, 266, 1114, 815, 26759, 663, 2262, 2077] (<class 'list'>), NEP-EOS: [2527, 1857, 855, 2710, 2874, 2262, 1112, 16996, 969, 663, 10, 8465, 597, 24844, 11, 266, 1114, 815, 26759, 663, 2262, 2077, 1502] (<class 'list'>)\n",
      "Checking sample 4\n",
      "ENG: [7581, 1404, 32388, 394, 549, 9, 85, 1615, 38961, 434, 662, 4998, 504, 3167, 2777, 394, 17567, 14, 17238, 14, 6912, 14, 15061, 14, 2032, 2422, 388, 603, 2175, 11267, 7007, 840, 3167, 3707, 1125, 664, 434, 707, 16] (<class 'list'>), NEP-SOS: [1501, 2783, 14698, 5655, 14, 11911, 14, 4101, 730, 14, 15628, 14, 264, 250, 45581, 3541, 14, 7757, 14, 10729, 6569, 740, 4722, 705, 16, 1709, 7483, 589, 36386, 1908, 2241, 825, 1741, 2254, 4752, 7662, 836, 1178, 979, 2191, 2591, 246] (<class 'list'>), NEP-EOS: [2783, 14698, 5655, 14, 11911, 14, 4101, 730, 14, 15628, 14, 264, 250, 45581, 3541, 14, 7757, 14, 10729, 6569, 740, 4722, 705, 16, 1709, 7483, 589, 36386, 1908, 2241, 825, 1741, 2254, 4752, 7662, 836, 1178, 979, 2191, 2591, 246, 1502] (<class 'list'>)\n",
      "üîç Testing DataLoader batching...\n",
      "‚úÖ Batch 1\n",
      " - Input shape : torch.Size([16, 63])\n",
      " - Target shape: torch.Size([16, 63])\n",
      " - Output shape: torch.Size([16, 63])\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Dataset & DataLoader\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, input_data, target_data, output_data):\n",
    "        self.input_data = input_data\n",
    "        self.target_data = target_data\n",
    "        self.output_data = output_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_data[idx], self.target_data[idx], self.output_data[idx]\n",
    "\n",
    "def pad_batch(batch):\n",
    "    input_seqs, target_seqs, output_seqs = zip(*batch)\n",
    "\n",
    "    def validate(group, name):\n",
    "        for i, seq in enumerate(group):\n",
    "            if isinstance(seq, int):\n",
    "                raise TypeError(f\"‚ùå {name}[{i}] is an int instead of list: {seq}\")\n",
    "            if not isinstance(seq, list):\n",
    "                raise TypeError(f\"‚ùå {name}[{i}] is not list: {type(seq)} -> {seq}\")\n",
    "            for j, tok in enumerate(seq):\n",
    "                if not isinstance(tok, int):\n",
    "                    raise TypeError(f\"‚ùå {name}[{i}][{j}] is not int: {type(tok)} -> {tok}\")\n",
    "\n",
    "    validate(input_seqs, \"input_seqs\")\n",
    "    validate(target_seqs, \"target_seqs\")\n",
    "    validate(output_seqs, \"output_seqs\")\n",
    "\n",
    "    max_len = max(len(seq) for seq in input_seqs + target_seqs + output_seqs)\n",
    "    pad_tensor = lambda seq: seq + [PAD_ID] * (max_len - len(seq))\n",
    "\n",
    "    try:\n",
    "        return (\n",
    "            torch.tensor([pad_tensor(s) for s in input_seqs]),\n",
    "            torch.tensor([pad_tensor(s) for s in target_seqs]),\n",
    "            torch.tensor([pad_tensor(s) for s in output_seqs])\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è ERROR DURING TENSOR CONVERSION:\")\n",
    "        print(\"Sample input_seqs:\", input_seqs[:3])\n",
    "        print(\"Sample target_seqs:\", target_seqs[:3])\n",
    "        print(\"Sample output_seqs:\", output_seqs[:3])\n",
    "        raise e\n",
    "\n",
    "\n",
    "\n",
    "dataset = TranslationDataset(enco_eng_data, deco_nep_data_sos, deco_nep_data_eos)\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=pad_batch)\n",
    "for i in range(5):\n",
    "    print(f\"Checking sample {i}\")\n",
    "    x, y, z = enco_eng_data[i], deco_nep_data_sos[i], deco_nep_data_eos[i]\n",
    "    print(f\"ENG: {x} ({type(x)}), NEP-SOS: {y} ({type(y)}), NEP-EOS: {z} ({type(z)})\")\n",
    "    for t in [x, y, z]:\n",
    "        assert isinstance(t, list), f\"‚ùå Not list: {t}\"\n",
    "        for token in t:\n",
    "            assert isinstance(token, int), f\"‚ùå Not int: {token} in {t}\"\n",
    "print(\"üîç Testing DataLoader batching...\")\n",
    "for batch_idx, (src, tgt, out) in enumerate(train_loader):\n",
    "    print(f\"‚úÖ Batch {batch_idx+1}\")\n",
    "    print(\" - Input shape :\", src.shape)\n",
    "    print(\" - Target shape:\", tgt.shape)\n",
    "    print(\" - Output shape:\", out.shape)\n",
    "    break  # Just check the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79142c55-12c6-4362-b2dc-e05d38db8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Transformer Model\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, embd, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(embd, heads, dropout=dropout, batch_first=True)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embd, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, embd)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(embd)\n",
    "        self.norm2 = nn.LayerNorm(embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_out, _ = self.attn(x, x, x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        ff_out = self.ff(x)\n",
    "        return self.norm2(x + ff_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c68e3bec-c546-4426-817b-000aa2c84ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embd, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embd, heads, dropout=dropout, batch_first=True)\n",
    "        self.cross_attn = nn.MultiheadAttention(embd, heads, dropout=dropout, batch_first=True)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embd, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, embd)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(embd)\n",
    "        self.norm2 = nn.LayerNorm(embd)\n",
    "        self.norm3 = nn.LayerNorm(embd)\n",
    "\n",
    "    def forward(self, x, enc_out):\n",
    "        self_attn_out, _ = self.self_attn(x, x, x, attn_mask=torch.triu(torch.ones(x.size(1), x.size(1)) * float('-inf'), diagonal=1).to(x.device))\n",
    "        x = self.norm1(x + self_attn_out)\n",
    "        cross_attn_out, _ = self.cross_attn(x, enc_out, enc_out)\n",
    "        x = self.norm2(x + cross_attn_out)\n",
    "        ff_out = self.ff(x)\n",
    "        return self.norm3(x + ff_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36c59a64-d037-40d3-9e5c-22fd71a8024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embd, heads, layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embd)\n",
    "        self.pe = nn.Embedding(500, embd)\n",
    "        self.encoder = nn.Sequential(*[EncoderBlock(embd, heads, dropout) for _ in range(layers)])\n",
    "        self.decoder = nn.ModuleList([DecoderBlock(embd, heads, dropout) for _ in range(layers)])\n",
    "        self.ln = nn.LayerNorm(embd)\n",
    "        self.out = nn.Linear(embd, vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        seq_len = src.size(1)\n",
    "        pos = torch.arange(seq_len, device=src.device).unsqueeze(0)\n",
    "        src = self.embed(src) + self.pe(pos)\n",
    "        enc_out = self.encoder(src)\n",
    "\n",
    "        tgt_len = tgt.size(1)\n",
    "        pos_t = torch.arange(tgt_len, device=src.device).unsqueeze(0)\n",
    "        tgt = self.embed(tgt) + self.pe(pos_t)\n",
    "        for layer in self.decoder:\n",
    "            tgt = layer(tgt, enc_out)\n",
    "\n",
    "        return self.out(self.ln(tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0110c900-4a9a-457b-8d3d-75ad8bbccdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|‚ñè         | 158/11084 [04:12<4:50:49,  1.60s/it] \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")  # or 'cuda' if available\n",
    "model = TranslationModel(vocab_size=50000, embd=256, heads=8, layers=4, dropout=0.1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
    "\n",
    "train_loss = []\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, tgt, out in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        src, tgt, out = src.to(device), tgt.to(device), out.to(device)\n",
    "        logits = model(src, tgt)\n",
    "        loss = loss_fn(logits.view(-1, logits.size(-1)), out.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg = total_loss / len(train_loader)\n",
    "    train_loss.append(avg)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg:.4f}\")\n",
    "    torch.save(model.state_dict(), f\"transformer_epoch{epoch+1}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d17a3-f73f-4b33-a8b0-2e41185ed71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Step 10: Plot Loss\n",
    "plt.plot(train_loss, marker='o')\n",
    "plt.title(\"Transformer NMT Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebbc593-3646-48ac-a0d7-f6dc86164140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Translation function\n",
    "def translate(sentence, max_len=30):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = torch.tensor([encode_ids(eng_tok, sentence)]).to('cuda')\n",
    "        pos = torch.arange(input_ids.size(1), device='cuda').unsqueeze(0)\n",
    "        enc_out = model.encoder(model.embed(input_ids) + model.pe(pos))\n",
    "\n",
    "        tgt_ids = torch.tensor([[SOS_ID]]).to('cuda')\n",
    "        for _ in range(max_len):\n",
    "            pos_t = torch.arange(tgt_ids.size(1), device='cuda').unsqueeze(0)\n",
    "            x = model.embed(tgt_ids) + model.pe(pos_t)\n",
    "            for layer in model.decoder:\n",
    "                x = layer(x, enc_out)\n",
    "            output = model.out(model.ln(x))\n",
    "            next_token = output[:, -1, :].argmax(dim=-1)\n",
    "            tgt_ids = torch.cat([tgt_ids, next_token.unsqueeze(1)], dim=1)\n",
    "            if next_token.item() == EOS_ID:\n",
    "                break\n",
    "        return nep_tok.decode(tgt_ids[0, 1:-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea4afc-5d08-4f25-b985-907da855acc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m refs = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m50\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     pred = \u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meng_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     ref = nep_data[i]\n\u001b[32m      7\u001b[39m     preds.append(pred)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtranslate\u001b[39m\u001b[34m(sentence, max_len)\u001b[39m\n\u001b[32m      3\u001b[39m model.eval()\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     input_ids = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencode_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43meng_tok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     pos = torch.arange(input_ids.size(\u001b[32m1\u001b[39m), device=\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m).unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m      7\u001b[39m     enc_out = model.encoder(model.embed(input_ids) + model.pe(pos))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/fyp/env/lib/python3.12/site-packages/torch/cuda/__init__.py:372\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m    371\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mLAZY\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[32m    376\u001b[39m _tls.is_initializing = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# Step 12: Evaluate with BLEU\n",
    "preds = []\n",
    "refs = []\n",
    "for i in range(50):\n",
    "    pred = translate(eng_data[i])\n",
    "    ref = nep_data[i]\n",
    "    preds.append(pred)\n",
    "    refs.append([ref])\n",
    "print(\"BLEU Score:\", corpus_bleu(preds, refs).score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
